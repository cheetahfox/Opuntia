--- a/include/uapi/linux/if_tunnel.h
+++ b/include/uapi/linux/if_tunnel.h
@@ -35,6 +35,10 @@ struct ip_tunnel_parm {
 	__be32			i_key;
 	__be32			o_key;
 	struct iphdr		iph;
+        struct timer_list               *timer;
+        int             ka_interval;
+        int             ka_retries;
+        int             ka_cur_retries;
 };
 
 enum {
--- a/net/ipv4/ip_gre.c
+++ b/net/ipv4/ip_gre.c
@@ -32,6 +32,7 @@
 #include <linux/netfilter_ipv4.h>
 #include <linux/etherdevice.h>
 #include <linux/if_ether.h>
+#include <linux/timer.h>
 
 #include <net/sock.h>
 #include <net/ip.h>
@@ -117,6 +118,7 @@ MODULE_PARM_DESC(log_ecn_error, "Log pac
 
 static struct rtnl_link_ops ipgre_link_ops __read_mostly;
 static int ipgre_tunnel_init(struct net_device *dev);
+static void ipgre_keepalive_timer(unsigned long data);
 
 static int ipgre_net_id __read_mostly;
 static int gre_tap_net_id __read_mostly;
@@ -335,6 +337,11 @@ static int ipgre_rcv(struct sk_buff *skb
 				  iph->saddr, iph->daddr, tpi.key);
 
 	if (tunnel) {
+		if (skb->protocol == 0) {
+			tunnel->parms.ka_cur_retries = tunnel->parms.ka_retries;
+			if (!netif_carrier_ok(tunnel->dev))
+				netif_carrier_on(tunnel->dev);
+		}
 		ip_tunnel_rcv(tunnel, skb, &tpi, log_ecn_error);
 		return 0;
 	}
@@ -495,11 +502,118 @@ out:
 	return NETDEV_TX_OK;
 }
 
+static void ipgre_keepalive_xmit(struct net_device *dev)
+{
+	struct ip_tunnel *tunnel = netdev_priv(dev);
+	struct iphdr *iph = &tunnel->parms.iph;
+	// 2 IP headers and 2 GRE headers, tunnel->hlen = IP header + GRE hreader
+	struct sk_buff *skb = dev_alloc_skb(tunnel->hlen * 2);
+	struct iphdr *inner_iph;
+
+	skb_reserve(skb, tunnel->hlen);
+	skb->dev = dev;
+	skb->pkt_type = PACKET_OUTGOING;
+	skb->ip_summed = CHECKSUM_NONE;
+	skb->protocol = htons(ETH_P_IP);
+	skb->transport_header = skb->network_header;
+	skb_reset_network_header(skb);
+
+	inner_iph = (struct iphdr*) skb_put(skb, tunnel->hlen);
+	inner_iph->saddr = iph->daddr;
+	inner_iph->daddr = iph->saddr;
+	inner_iph->protocol = IPPROTO_GRE;
+
+	inner_iph->version	=	4;
+	inner_iph->ihl		=	sizeof(struct iphdr) >> 2;
+	inner_iph->frag_off	=	0;
+	inner_iph->ttl		=	255;
+	inner_iph->tos		=	0;
+	inner_iph->tot_len = htons(skb->len);
+
+	((__be16*)(inner_iph+1))[0] = tunnel->parms.o_flags;
+	((__be16*)(inner_iph+1))[1] = 0;
+
+	if (tunnel->parms.o_flags&(GRE_KEY|GRE_CSUM|GRE_SEQ)) {
+		__be32 *ptr = (__be32*)(((u8*)inner_iph) + tunnel->hlen - 4);
+
+		if (tunnel->parms.o_flags&GRE_SEQ) {
+			++tunnel->o_seqno;
+			*ptr = htonl(tunnel->o_seqno);
+			ptr--;
+		}
+		if (tunnel->parms.o_flags&GRE_KEY) {
+			*ptr = tunnel->parms.o_key;
+			ptr--;
+		}
+		if (tunnel->parms.o_flags&GRE_CSUM) {
+			*ptr = 0;
+			*(__sum16*)ptr = ip_compute_csum((void*)(inner_iph+1), skb->len - sizeof(struct iphdr));
+		}
+	}
+
+	inner_iph->check = 0;
+	inner_iph->check = ip_fast_csum((unsigned char *)inner_iph, inner_iph->ihl);
+
+	ipgre_xmit(skb, dev);
+}
+
+static void ipgre_keepalive_schedule(struct ip_tunnel *tunnel)
+{
+	struct ip_tunnel_parm *parms = &tunnel->parms;
+
+	parms->timer->function = ipgre_keepalive_timer;
+	/* First keepalive sent in 1 jiffie */
+	if (parms->timer->data == 0)
+		parms->timer->expires = jiffies + 1;
+	else
+		parms->timer->expires = jiffies + tunnel->parms.ka_interval * HZ;
+	parms->timer->data = (unsigned long) tunnel;
+	add_timer(parms->timer);
+}
+
+static void ipgre_keepalive_timer(unsigned long data)
+{
+	struct ip_tunnel *tunnel = (struct ip_tunnel*) data;
+	
+	if (tunnel->parms.ka_cur_retries > 0 && --tunnel->parms.ka_cur_retries == 0) {
+		netif_carrier_off(tunnel->dev);
+	}
+
+	ipgre_keepalive_xmit(tunnel->dev);
+	ipgre_keepalive_schedule(tunnel);
+}
+
+void ip_gre_keepalive_setup(struct ip_tunnel *t, struct net_device *dev, int on)
+{
+	struct in_device *in_dev = __in_dev_get_rtnl(dev);
+	if (on) {
+		if (!t->parms.timer)
+			t->parms.timer = kmalloc(sizeof(struct timer_list), GFP_ATOMIC);
+		init_timer(t->parms.timer);
+		t->parms.timer->data = 0;
+		netif_carrier_off(dev);
+		if (in_dev)
+			IPV4_DEVCONF(in_dev->cnf, ACCEPT_LOCAL) = 1;
+		t->parms.ka_cur_retries = t->parms.ka_retries;
+		ipgre_keepalive_schedule(t);
+	}
+	else {
+		del_timer(t->parms.timer);
+		kfree(t->parms.timer);
+		t->parms.timer = NULL;
+		if (!netif_carrier_ok(dev))
+			netif_carrier_on(dev);
+		if (in_dev)
+			IPV4_DEVCONF(in_dev->cnf, ACCEPT_LOCAL) = 0;
+	}
+}
+
 static int ipgre_tunnel_ioctl(struct net_device *dev,
 			      struct ifreq *ifr, int cmd)
 {
 	int err = 0;
 	struct ip_tunnel_parm p;
+	struct ip_tunnel *t = netdev_priv(dev);
 
 	if (copy_from_user(&p, ifr->ifr_ifru.ifru_data, sizeof(p)))
 		return -EFAULT;
@@ -512,10 +626,36 @@ static int ipgre_tunnel_ioctl(struct net
 	p.i_flags = gre_flags_to_tnl_flags(p.i_flags);
 	p.o_flags = gre_flags_to_tnl_flags(p.o_flags);
 
+	if (cmd == SIOCDELTUNNEL && t && t->parms.timer) {
+		del_timer(t->parms.timer);
+		kfree(t->parms.timer);
+		t->parms.timer = NULL;
+	}
+
 	err = ip_tunnel_ioctl(dev, &p, cmd);
 	if (err)
 		return err;
 
+	t->parms.ka_interval = p.ka_interval;
+	t->parms.ka_retries = p.ka_retries;
+
+	if (cmd == SIOCCHGTUNNEL) {
+		t->parms.iph.ttl = p.iph.ttl;
+		t->parms.iph.tos = p.iph.tos;
+		t->parms.iph.frag_off = p.iph.frag_off;
+
+		if (!t->parms.timer && t->parms.ka_interval > 0 && t->parms.ka_retries > 0) {
+			ip_gre_keepalive_setup(t, t->dev, 1);
+		} else if (t->parms.timer && (t->parms.ka_interval <= 0 || t->parms.ka_retries <= 0)) {
+			ip_gre_keepalive_setup(t, t->dev, 0);
+		}
+	} else if (cmd == SIOCADDTUNNEL) {
+		t->parms.timer = NULL;
+		if (t->parms.ka_interval > 0 && t->parms.ka_retries > 0) {
+			ip_gre_keepalive_setup(t, t->dev, 1);
+		}
+	}
+
 	p.i_flags = tnl_flags_to_gre_flags(p.i_flags);
 	p.o_flags = tnl_flags_to_gre_flags(p.o_flags);
 
